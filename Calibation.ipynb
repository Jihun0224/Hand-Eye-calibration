{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57979861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, glob, os, time, matplotlib.pyplot as plt\n",
    "import pyrealsense2 as rs\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import rby1_sdk as rb\n",
    "import json\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0715917",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"calib_data\"\n",
    "IMG_DIR = os.path.join(SAVE_DIR,\"images\"); os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "K_FILE = \"K_1280x720.npy\"\n",
    "D_FILE = \"D_1280x720.npy\"\n",
    "PRESET_FILE = \"rs_locked_preset.json\"\n",
    "ADDRESS = \"192.168.30.1:50051\"\n",
    "MODEL = \"a\"\n",
    "POWER = \".*\"\n",
    "BASE_INDEX, LINK_TORSO_5_INDEX, EE_RIGHT_INDEX, EE_LEFT_INDEX = 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9c3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_positions() -> list:\n",
    "    robot = rb.create_robot(ADDRESS, MODEL)\n",
    "    robot.connect()\n",
    "    if not robot.is_connected():\n",
    "        print(\"Robot is not connected\")\n",
    "        exit(1)\n",
    "    if not robot.is_power_on(POWER):\n",
    "        rv = robot.power_on(POWER)\n",
    "        if not rv:\n",
    "            print(\"Failed to power on\")\n",
    "            exit(1)\n",
    "    robot.reset_fault_control_manager()\n",
    "    robot.enable_control_manager()\n",
    "\n",
    "    robot_state = robot.get_state()\n",
    "    body = [round(x, 3) for x in robot_state.position[2:8]]\n",
    "    right_arm = [round(x, 3) for x in robot_state.position[8:15]]\n",
    "    left_arm = [round(x, 3) for x in robot_state.position[15:22]]\n",
    "    head = [round(x,3) for x in robot_state.position[22:]]\n",
    "    result = [\n",
    "        body,\n",
    "        right_arm,\n",
    "        left_arm,\n",
    "        head\n",
    "    ]\n",
    "    return result\n",
    "\n",
    "def get_flange_homogeneous() -> np.array:\n",
    "    robot = rb.create_robot(ADDRESS, MODEL)\n",
    "    model = robot.model()\n",
    "    robot.connect()\n",
    "    \n",
    "    dyn_model = robot.get_dynamics()\n",
    "    dyn_state = dyn_model.make_state([\"base\", \"link_torso_5\", \"ee_right\", \"ee_left\"], model.robot_joint_names)\n",
    "    dyn_state.set_q(robot.get_state().position)\n",
    "    dyn_model.compute_forward_kinematics(dyn_state)\n",
    "    T_base2left = dyn_model.compute_transformation(dyn_state, BASE_INDEX, EE_LEFT_INDEX)\n",
    "    \n",
    "    print(T_base2left)\n",
    "\n",
    "    return T_base2left\n",
    "\n",
    "def matrix_to_quat_xyzw(Rm):\n",
    "    return R.from_matrix(Rm).as_quat().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb23c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_KD(k_path, d_path):\n",
    "    try:\n",
    "        K = np.load(k_path)\n",
    "    except Exception:\n",
    "        base = os.path.splitext(k_path)[0]\n",
    "        try:\n",
    "            K = np.load(base + \".npy\")\n",
    "        except Exception:\n",
    "            raise RuntimeError(f\"Cannot load K from {k_path}\")\n",
    "    try:\n",
    "        D = np.load(d_path)\n",
    "    except Exception:\n",
    "        base = os.path.splitext(d_path)[0]\n",
    "        try:\n",
    "            D = np.load(base + \"_D.npy\")\n",
    "        except Exception:\n",
    "            raise RuntimeError(f\"Cannot load D from {d_path}\")\n",
    "    return K, D\n",
    "\n",
    "try:\n",
    "    K_mat, D_vec = load_KD(K_FILE, D_FILE)\n",
    "except Exception as e:\n",
    "    print(\"Warning: cannot load K/D now:\", e)\n",
    "    K_mat, D_vec = None, None\n",
    "\n",
    "IMG_DIR = \"calib_images\"\n",
    "SAVE_DIR = \"calib_records\"\n",
    "cols, rows, spacing = 4, 5, 0.02\n",
    "DISPLAY_SCALE = 0.50\n",
    "UNDISTORT_FOR_DETECT = False\n",
    "K_FILE = \"K_1280x720.npy\"\n",
    "D_FILE = \"K_1280x720.npy\"\n",
    "PRESET_FILE = \"rs_locked_preset.json\"\n",
    "SAVE_DEBUG_IMAGES = True\n",
    "PATCH_DIR = \"point_patches\"\n",
    "DEBUG_DIR = \"debug_images\"\n",
    "\n",
    "\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(PATCH_DIR, exist_ok=True)\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "K_mat, D_vec = load_KD(K_FILE, D_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6177152",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = rb.create_robot(ADDRESS, MODEL)\n",
    "robot.connect()\n",
    "calibration_pos = [[0.0, 0.582, -1.122, 0.592, 0.0, 0.0], [-0.477, -0.185, -0.128, -2.261, -0.182, 1.702, 0.0], [-0.477, 0.185, 0.128, -2.261, 0.182, 1.702, -0.0]]\n",
    "\n",
    "def move_head(pos):\n",
    "    robot = rb.create_robot(ADDRESS, MODEL)\n",
    "    robot.connect()\n",
    "    head_0, head_1 = pos\n",
    "    rc_builder = rb.RobotCommandBuilder().set_command(\n",
    "        rb.ComponentBasedCommandBuilder().set_head_command(\n",
    "            rb.HeadCommandBuilder()\n",
    "            .set_command(rb.JointPositionCommandBuilder()\n",
    "            .set_command_header(rb.CommandHeaderBuilder().set_control_hold_time(0.5))\n",
    "            .set_minimum_time(1)\n",
    "            .set_position([head_0, head_1])\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    rc = robot.send_command(rc_builder).get()\n",
    "    return rc.finish_code == rb.RobotCommandFeedback.FinishCode.Ok\n",
    "\n",
    "def move_to(pos = calibration_pos, minimum_time = 3):\n",
    "    torso, right_arm, left_arm = pos\n",
    "    rc_builder = rb.RobotCommandBuilder().set_command(\n",
    "        rb.ComponentBasedCommandBuilder().set_body_command(\n",
    "            rb.BodyComponentBasedCommandBuilder()\n",
    "            # Set Torso Command with Joint Position Command\n",
    "            .set_torso_command(\n",
    "                rb.JointPositionCommandBuilder()\n",
    "                .set_command_header(rb.CommandHeaderBuilder().set_control_hold_time(0.5))  # For staturation\n",
    "                .set_minimum_time(minimum_time)\n",
    "                .set_position(torso)\n",
    "            )\n",
    "            # Set Right Command with Joint Position Command\n",
    "            .set_right_arm_command(\n",
    "                rb.JointPositionCommandBuilder()\n",
    "                .set_command_header(rb.CommandHeaderBuilder().set_control_hold_time(0.5))\n",
    "                .set_minimum_time(minimum_time)\n",
    "                .set_position(right_arm)\n",
    "            )\n",
    "            # Set Left Command with Joint Position Command\n",
    "            .set_left_arm_command(\n",
    "                rb.JointPositionCommandBuilder()\n",
    "                .set_command_header(rb.CommandHeaderBuilder().set_control_hold_time(0.5))\n",
    "                .set_minimum_time(minimum_time)\n",
    "                .set_position(left_arm)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    rc = robot.send_command(rc_builder).get()\n",
    "    return rc.finish_code == rb.RobotCommandFeedback.FinishCode.Ok\n",
    "    \n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any, Union\n",
    "\n",
    "def load_joints_from_json_dir(dir_path: str,\n",
    "                              json_glob: str = \"he_record_*.json\") -> List[Union[List[float], Dict[str, Any]]]:\n",
    "\n",
    "    files = sorted([f for f in os.listdir(dir_path) if f.endswith(\".json\") and json_glob.replace(\"*\", \"\") in f or f.startswith(json_glob.split(\"*\")[0])])\n",
    "    if not files:\n",
    "        files = sorted([f for f in os.listdir(dir_path) if f.endswith(\".json\")])\n",
    "\n",
    "    results = []\n",
    "    for fn in files:\n",
    "        full = os.path.join(dir_path, fn)\n",
    "        try:\n",
    "            with open(full, \"r\") as fh:\n",
    "                rec = json.load(fh)\n",
    "        except Exception as e:\n",
    "            print(f\"failed to load {full}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # bd = rec.get(\"board_detection\")\n",
    "        # if not bd:\n",
    "        #     continue\n",
    "        # if not bd.get(\"found\", False):\n",
    "        #     continue\n",
    "\n",
    "        joints = rec.get(\"joints\")\n",
    "        if joints is None:\n",
    "            print(f\"{fn} has no 'joints' field; skipping\")\n",
    "            continue\n",
    "        out_val = joints\n",
    "\n",
    "        results.append(out_val)\n",
    "\n",
    "    print(f\"[INFO] scanned {len(files)} json files in '{dir_path}'. found {len(results)} frames with board_detection.found==True\")\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb868e2",
   "metadata": {},
   "source": [
    "카메라(컬러+정렬된 depth) 프레임을 저장하고, 체커(원형)로 2D 코너 검출 → 각 코너에 대해 depth(median)로 3D 포인트 복원 → solvePnP(또는 RANSAC)로 target→camera pose 추정 → 로봇에서 gripper→base(H_base_grip) 읽어서 (gripper↔base, target↔cam) 페어를 모아 hand-eye 보정 → depth 기반으로 포인트 비교/검증하는 플로우."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23933c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:\n",
      " [[309.60391334   0.         680.48736427]\n",
      " [  0.         841.62754512 393.05409321]\n",
      " [  0.           0.           1.        ]]\n",
      "D: [[ 6.19763036e+01 -9.70926778e+02 -6.50846595e-01  1.21165149e+00\n",
      "   4.99324976e+03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "K = np.load(\"K_1280x720.npy\")\n",
    "print(\"K:\\n\", K)\n",
    "D = np.load(\"D_1280x720.npy\") if os.path.exists(\"D_1280x720.npy\") else None\n",
    "print(\"D:\", D)\n",
    "assert K.shape == (3,3) and K[0,0]>0 and K[1,1]>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f242aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objp[0:8]:\n",
      " [[0.   0.   0.  ]\n",
      " [0.08 0.   0.  ]\n",
      " [0.16 0.   0.  ]\n",
      " [0.24 0.   0.  ]\n",
      " [0.32 0.   0.  ]\n",
      " [0.04 0.04 0.  ]\n",
      " [0.12 0.04 0.  ]\n",
      " [0.2  0.04 0.  ]]\n",
      "objp count: 20\n"
     ]
    }
   ],
   "source": [
    "def make_objp_for_pattern(pattern_type):\n",
    "    if pattern_type == \"asymmetric\":\n",
    "        objp = np.zeros((cols*rows,3), np.float64)\n",
    "        idxp = 0\n",
    "        for j in range(rows):\n",
    "            for i in range(cols):\n",
    "                x = (2 * i + (j % 2)) * spacing\n",
    "                y = j * spacing\n",
    "                objp[idxp,0] = x; objp[idxp,1] = y; idxp += 1\n",
    "        return objp\n",
    "    else:\n",
    "        objp = np.zeros((cols*rows,3), np.float64)\n",
    "        grid = np.mgrid[0:cols, 0:rows].T.reshape(-1,2)\n",
    "        objp[:,:2] = grid * spacing\n",
    "        return objp\n",
    "objp = make_objp_for_pattern(\"asymmetric\")\n",
    "print(\"objp[0:8]:\\n\", objp[:8])\n",
    "print(\"objp count:\", len(objp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cffaf62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: debug_images/he_img_0000_idx_depth.png\n",
      "saved: debug_images/he_img_0001_idx_depth.png\n",
      "saved: debug_images/he_img_0002_idx_depth.png\n",
      "saved: debug_images/he_img_0003_idx_depth.png\n",
      "saved: debug_images/he_img_0004_idx_depth.png\n",
      "saved: debug_images/he_img_0005_idx_depth.png\n",
      "saved: debug_images/he_img_0006_idx_depth.png\n",
      "saved: debug_images/he_img_0007_idx_depth.png\n",
      "saved: debug_images/he_img_0008_idx_depth.png\n",
      "saved: debug_images/he_img_0009_idx_depth.png\n",
      "saved: debug_images/he_img_0010_idx_depth.png\n",
      "saved: debug_images/he_img_0011_idx_depth.png\n",
      "saved: debug_images/he_img_0012_idx_depth.png\n",
      "saved: debug_images/he_img_0013_idx_depth.png\n",
      "saved: debug_images/he_img_0014_idx_depth.png\n",
      "saved: debug_images/he_img_0015_idx_depth.png\n",
      "saved: debug_images/he_img_0016_idx_depth.png\n",
      "saved: debug_images/he_img_0017_idx_depth.png\n",
      "saved: debug_images/he_img_0018_idx_depth.png\n",
      "saved: debug_images/he_img_0019_idx_depth.png\n",
      "saved: debug_images/he_img_0020_idx_depth.png\n",
      "saved: debug_images/he_img_0021_idx_depth.png\n",
      "saved: debug_images/he_img_0022_idx_depth.png\n",
      "saved: debug_images/he_img_0023_idx_depth.png\n",
      "no imgpts - skip calib_records/he_record_0024.json\n",
      "saved: debug_images/he_img_0025_idx_depth.png\n",
      "saved: debug_images/he_img_0026_idx_depth.png\n",
      "saved: debug_images/he_img_0027_idx_depth.png\n",
      "saved: debug_images/he_img_0028_idx_depth.png\n",
      "saved: debug_images/he_img_0029_idx_depth.png\n",
      "saved: debug_images/he_img_0030_idx_depth.png\n",
      "csv written: debug_images/points_depths_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json, csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "JSON_DIR = \"calib_records\"\n",
    "IMG_DIR = \"calib_images\"\n",
    "OUT_DIR = \"debug_images\"\n",
    "CSV_OUT = os.path.join(OUT_DIR, \"points_depths_summary.csv\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "use_json_mapping = True\n",
    "\n",
    "def depth_to_color(depth, dmin, dmax):\n",
    "    if depth is None or (isinstance(depth, float) and np.isnan(depth)):\n",
    "        return (128,128,128)\n",
    "    if dmax <= dmin:\n",
    "        t = 0.5\n",
    "    else:\n",
    "        t = float((depth - dmin) / float(dmax - dmin))\n",
    "        t = max(0.0, min(1.0, t))\n",
    "    G = int(round(255 * (1.0 - t)))\n",
    "    R = int(round(255 * t))\n",
    "    return (0, G, R)\n",
    "\n",
    "def draw_and_save(img_path, imgpts, depths, out_path, csv_rows=None):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(\"img open fail:\", img_path)\n",
    "        return False\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    if depths is None:\n",
    "        depths = [float('nan')] * len(imgpts)\n",
    "    depths_arr = np.array([d if d is not None else np.nan for d in depths], dtype=np.float64)\n",
    "    finite = depths_arr[np.isfinite(depths_arr)]\n",
    "    if finite.size > 0:\n",
    "        dmin = float(np.percentile(finite, 5))\n",
    "        dmax = float(np.percentile(finite, 95))\n",
    "        if dmax <= dmin:\n",
    "            dmin = float(finite.min()); dmax = float(finite.max())\n",
    "    else:\n",
    "        dmin = 0.0; dmax = 1.0\n",
    "    for i, (u, v) in enumerate(imgpts):\n",
    "        ui = int(round(u)); vi = int(round(v))\n",
    "        depth_val = float(depths_arr[i]) if i < len(depths_arr) else float('nan')\n",
    "        color = depth_to_color(depth_val, dmin, dmax)\n",
    "        cv2.circle(img, (ui, vi), radius=6, color=color, thickness=2)\n",
    "        cv2.putText(img, str(i), (ui + 8, vi + 4), font, 0.5, (0,0,0), thickness=2, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(img, str(i), (ui + 8, vi + 4), font, 0.5, (255,255,255), thickness=1, lineType=cv2.LINE_AA)\n",
    "        depth_text = f\"{depth_val:.3f} m\" if np.isfinite(depth_val) else \"NaN\"\n",
    "        tx, ty = ui + 8, vi + 22\n",
    "        cv2.putText(img, depth_text, (tx, ty), font, 0.45, (0,0,0), thickness=3, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(img, depth_text, (tx, ty), font, 0.45, (255,255,255), thickness=1, lineType=cv2.LINE_AA)\n",
    "        if i < len(imgpts) - 1:\n",
    "            p1 = (ui, vi)\n",
    "            p2 = tuple(np.round(imgpts[i+1]).astype(int))\n",
    "            cv2.line(img, p1, p2, (200,200,200), 1)\n",
    "        if csv_rows is not None:\n",
    "            csv_rows.append({\n",
    "                \"image\": os.path.basename(img_path),\n",
    "                \"idx\": i,\n",
    "                \"u\": float(u),\n",
    "                \"v\": float(v),\n",
    "                \"depth_m\": (float(depth_val) if np.isfinite(depth_val) else None)\n",
    "            })\n",
    "    cv2.imwrite(out_path, img)\n",
    "    return True\n",
    "\n",
    "if use_json_mapping:\n",
    "    json_files = sorted(glob.glob(os.path.join(JSON_DIR, \"he_record_*.json\")))\n",
    "    if not json_files:\n",
    "        print(\"no json in\", JSON_DIR)\n",
    "\n",
    "    all_csv_rows = []\n",
    "    for jf in json_files:\n",
    "        try:\n",
    "            rec = json.load(open(jf, \"r\"))\n",
    "        except Exception as e:\n",
    "            print(\"json read fail:\", jf); continue\n",
    "        bd = rec.get(\"board_detection\", {})\n",
    "        imgpts = bd.get(\"imgpts2d\")\n",
    "        depths = bd.get(\"depths_m\", None)\n",
    "        if not imgpts:\n",
    "            print(\"no imgpts - skip\", jf); continue\n",
    "        imgpts = np.array(imgpts, dtype=np.float64)\n",
    "        imgname = rec.get(\"image\")\n",
    "        if imgname:\n",
    "            img_path = os.path.join(IMG_DIR, imgname)\n",
    "        else:\n",
    "            base = os.path.basename(jf).replace(\"he_record_\", \"he_img_\").replace(\".json\", \".png\")\n",
    "            img_path = os.path.join(IMG_DIR, base)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(\"img not found:\", img_path); continue\n",
    "        out_name = os.path.splitext(os.path.basename(img_path))[0] + \"_idx_depth.png\"\n",
    "        out_path = os.path.join(OUT_DIR, out_name)\n",
    "        csv_rows_frame = []\n",
    "        ok = draw_and_save(img_path, imgpts, depths, out_path, csv_rows=csv_rows_frame)\n",
    "        if ok:\n",
    "            print(\"saved:\", out_path)\n",
    "            all_csv_rows.extend(csv_rows_frame)\n",
    "        else:\n",
    "            print(\"fail:\", img_path)\n",
    "    if all_csv_rows:\n",
    "        keys = [\"image\", \"idx\", \"u\", \"v\", \"depth_m\"]\n",
    "        with open(CSV_OUT, \"w\", newline='') as cf:\n",
    "            writer = csv.DictWriter(cf, fieldnames=keys)\n",
    "            writer.writeheader()\n",
    "            for r in all_csv_rows:\n",
    "                writer.writerow(r)\n",
    "        print(\"csv written:\", CSV_OUT)\n",
    "    else:\n",
    "        print(\"no rows\")\n",
    "else:\n",
    "    img_files = sorted(glob.glob(os.path.join(IMG_DIR, \"*.*\")))\n",
    "    all_csv_rows = []\n",
    "    for img_path in img_files:\n",
    "        base = os.path.basename(img_path)\n",
    "        json_guess = base.replace(\"he_img_\", \"he_record_\").rsplit(\".\", 1)[0] + \".json\"\n",
    "        jf = os.path.join(JSON_DIR, json_guess)\n",
    "        if not os.path.exists(jf):\n",
    "            print(\"skip no json for\", img_path); continue\n",
    "        rec = json.load(open(jf, \"r\"))\n",
    "        bd = rec.get(\"board_detection\", {})\n",
    "        imgpts = bd.get(\"imgpts2d\")\n",
    "        depths = bd.get(\"depths_m\", None)\n",
    "        if not imgpts:\n",
    "            print(\"no imgpts - skip\", jf); continue\n",
    "        imgpts = np.array(imgpts, dtype=np.float64)\n",
    "        out_name = os.path.splitext(base)[0] + \"_idx_depth.png\"\n",
    "        out_path = os.path.join(OUT_DIR, out_name)\n",
    "        csv_rows_frame = []\n",
    "        ok = draw_and_save(img_path, imgpts, depths, out_path, csv_rows=csv_rows_frame)\n",
    "        if ok:\n",
    "            print(\"saved:\", out_path)\n",
    "            all_csv_rows.extend(csv_rows_frame)\n",
    "        else:\n",
    "            print(\"fail:\", img_path)\n",
    "    if all_csv_rows:\n",
    "        keys = [\"image\", \"idx\", \"u\", \"v\", \"depth_m\"]\n",
    "        with open(CSV_OUT, \"w\", newline='') as cf:\n",
    "            writer = csv.DictWriter(cf, fieldnames=keys)\n",
    "            writer.writeheader()\n",
    "            for r in all_csv_rows:\n",
    "                writer.writerow(r)\n",
    "        print(\"csv written:\", CSV_OUT)\n",
    "    else:\n",
    "        print(\"no rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85205f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HEAD_CAL_POSE = [math.radians(0), math.radians(-12)]\n",
    "move_head(HEAD_CAL_POSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a0d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warn: no pattern he_img_0000.png\n"
     ]
    }
   ],
   "source": [
    "import os, glob, cv2, json\n",
    "import numpy as np\n",
    "\n",
    "IMG_DIR = \"calib_images\"\n",
    "OUT_DIR = \"debug_detect\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# board guesses (adjust if your board is different)\n",
    "cols, rows = 5, 4   # pattern size (cols, rows) used in your pipeline\n",
    "use_asymmetric = True\n",
    "\n",
    "# blob detector variants to try\n",
    "def make_detector(variant=0):\n",
    "    p = cv2.SimpleBlobDetector_Params()\n",
    "    if variant == 0:\n",
    "        p.minThreshold=5; p.maxThreshold=220; p.thresholdStep=5\n",
    "        p.filterByArea=True; p.minArea=10; p.maxArea=50000\n",
    "        p.filterByCircularity=True; p.minCircularity=0.4\n",
    "        p.filterByInertia=True; p.minInertiaRatio=0.1\n",
    "        p.filterByConvexity=True; p.minConvexity=0.3\n",
    "        p.filterByColor=True; p.blobColor=255\n",
    "    elif variant == 1:\n",
    "        p.minThreshold=1; p.maxThreshold=240; p.thresholdStep=10\n",
    "        p.filterByArea=True; p.minArea=5; p.maxArea=100000\n",
    "        p.filterByCircularity=False\n",
    "        p.filterByInertia=False\n",
    "        p.filterByConvexity=False\n",
    "        p.filterByColor=True; p.blobColor=255\n",
    "    else:\n",
    "        p.minThreshold=10; p.maxThreshold=200; p.thresholdStep=10\n",
    "        p.filterByArea=True; p.minArea=30; p.maxArea=50000\n",
    "        p.filterByCircularity=True; p.minCircularity=0.6\n",
    "        p.filterByInertia=True; p.minInertiaRatio=0.2\n",
    "        p.filterByConvexity=True; p.minConvexity=0.6\n",
    "        p.filterByColor=True; p.blobColor=255\n",
    "    return cv2.SimpleBlobDetector_create(p)\n",
    "\n",
    "detectors = [make_detector(i) for i in range(3)]\n",
    "img_files = sorted(glob.glob(os.path.join(IMG_DIR, \"*.*\")))\n",
    "\n",
    "# try charuco if aruco present\n",
    "try:\n",
    "    aruco = cv2.aruco\n",
    "    has_aruco = True\n",
    "except Exception:\n",
    "    has_aruco = False\n",
    "\n",
    "for fp in img_files:\n",
    "    img = cv2.imread(fp)\n",
    "    if img is None:\n",
    "        print(\"fail: open\", fp); continue\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    success = False\n",
    "    info = []\n",
    "\n",
    "    # preprocessing variants\n",
    "    variants = [\n",
    "        (\"orig\", gray),\n",
    "        (\"blur\", cv2.GaussianBlur(gray, (5,5), 0)),\n",
    "        (\"equal\", cv2.equalizeHist(gray)),\n",
    "        (\"thresh\", cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2))\n",
    "    ]\n",
    "\n",
    "    for vname, g in variants:\n",
    "        if success: break\n",
    "        if use_asymmetric:\n",
    "            for det_i, det in enumerate(detectors):\n",
    "                try:\n",
    "                    flag = cv2.CALIB_CB_ASYMMETRIC_GRID\n",
    "                    ret, centers = cv2.findCirclesGrid(g, (cols, rows), flags=flag, blobDetector=det)\n",
    "                    if ret:\n",
    "                        out = img.copy()\n",
    "                        cv2.drawChessboardCorners(out, (cols, rows), centers, ret)\n",
    "                        outp = os.path.join(OUT_DIR, os.path.basename(fp).replace(\".\",f\"_asym_{vname}{det_i}.\"))\n",
    "                        outp = outp + \"png\"\n",
    "                        cv2.imwrite(outp, out)\n",
    "                        print(\"ok asym\", os.path.basename(fp), vname, \"det\", det_i)\n",
    "                        success = True\n",
    "                        break\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if success: break\n",
    "\n",
    "\n",
    "    if not success:\n",
    "        print(\"warn: no pattern\", os.path.basename(fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772af93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok: loaded K from json field\n",
      "ok: loaded D_1280x720.npy\n",
      "checking K/D ..\n",
      "ok: fx,fy 309.6 841.63\n",
      "ok: skew small\n",
      "ok: cx 680.49\n",
      "ok: cy 393.05\n",
      "D len (1, 5) values: [[61.9763, -970.9268, -0.6508, 1.2117, 4993.2498]]\n",
      "warn: large distortion coefficients -> likely wrong\n",
      "synthetic test ..\n",
      "synthetic: 19/20 points inside image (95.0%)\n",
      "ok: synthetic projection looks reasonable\n",
      "reprojection test on JSONs ..\n",
      "he_record_0000.json rmse=8986606.039 rmse_noD=326.999\n",
      "he_record_0001.json rmse=138768792.970 rmse_noD=562.455\n",
      "he_record_0002.json rmse=35911128424.579 rmse_noD=491.698\n",
      "he_record_0003.json rmse=317245281.049 rmse_noD=409.634\n",
      "he_record_0004.json rmse=37508428252.863 rmse_noD=697.768\n",
      "he_record_0005.json rmse=78.139 rmse_noD=83.028\n",
      "he_record_0006.json rmse=77.367 rmse_noD=82.213\n",
      "he_record_0007.json rmse=274.305 rmse_noD=152.232\n",
      "he_record_0008.json rmse=27508319447.232 rmse_noD=1019.701\n",
      "he_record_0009.json rmse=77.117 rmse_noD=85.286\n",
      "he_record_0010.json rmse=3154669819.498 rmse_noD=504.111\n",
      "he_record_0011.json rmse=68.817 rmse_noD=84.204\n",
      "he_record_0012.json rmse=46.327 rmse_noD=55.162\n",
      "he_record_0013.json rmse=102.743 rmse_noD=97.811\n",
      "he_record_0014.json rmse=118.500 rmse_noD=148.343\n",
      "he_record_0015.json rmse=333796611.573 rmse_noD=456.807\n",
      "he_record_0016.json rmse=195902965.940 rmse_noD=500.364\n",
      "he_record_0017.json rmse=110.840 rmse_noD=144.596\n",
      "he_record_0018.json rmse=1247225386943.082 rmse_noD=874.990\n",
      "he_record_0019.json rmse=124.157 rmse_noD=166.185\n",
      "he_record_0020.json rmse=316663715.681 rmse_noD=640.017\n",
      "he_record_0021.json rmse=274.531 rmse_noD=165.240\n",
      "he_record_0022.json rmse=148322841364927.531 rmse_noD=1322.423\n",
      "he_record_0023.json rmse=22385.346 rmse_noD=302.523\n",
      "he_record_0025.json rmse=2510.226 rmse_noD=215.011\n",
      "he_record_0026.json rmse=316791655.435 rmse_noD=442.303\n",
      "he_record_0027.json rmse=316663484.045 rmse_noD=493.623\n",
      "he_record_0028.json rmse=316830226.630 rmse_noD=484.996\n",
      "he_record_0029.json rmse=467.731 rmse_noD=143.527\n",
      "he_record_0030.json rmse=105.023 rmse_noD=140.821\n",
      "summary mean rmse: 4989213699132.51\n",
      "warn: frames where zero-D better (possible bad D):\n",
      " - he_record_0000.json rmse 8986606.04 rmse_noD 327.0\n",
      " - he_record_0001.json rmse 138768792.97 rmse_noD 562.46\n",
      " - he_record_0002.json rmse 35911128424.58 rmse_noD 491.7\n",
      " - he_record_0003.json rmse 317245281.05 rmse_noD 409.63\n",
      " - he_record_0004.json rmse 37508428252.86 rmse_noD 697.77\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "JSON_DIR = \"calib_records\"\n",
    "K_FILE_FALLBACK = \"K_1280x720.npy\"\n",
    "D_FILE_FALLBACK = \"D_1280x720.npy\"\n",
    "IMG_W = 1280\n",
    "IMG_H = 720\n",
    "COLS, ROWS, SPACING = 5, 4, 0.04\n",
    "MAX_D_MAG_WARN = 1e3\n",
    "RMSE_GOOD = 5.0\n",
    "\n",
    "def load_KD_from_files(sample_json=None):\n",
    "    K = None; D = None\n",
    "    if sample_json:\n",
    "        kinf = sample_json.get(\"camera_intrinsics\")\n",
    "        if kinf and os.path.exists(kinf):\n",
    "            try:\n",
    "                K = np.load(kinf)\n",
    "                print(\"ok: loaded K from json field\")\n",
    "            except Exception:\n",
    "                print(\"warn: failed load K from json field\")\n",
    "    if K is None and os.path.exists(K_FILE_FALLBACK):\n",
    "        K = np.load(K_FILE_FALLBACK); print(\"ok: loaded\", K_FILE_FALLBACK)\n",
    "    if os.path.exists(D_FILE_FALLBACK):\n",
    "        D = np.load(D_FILE_FALLBACK); print(\"ok: loaded\", D_FILE_FALLBACK)\n",
    "    if K is None:\n",
    "        raise RuntimeError(\"err: K not found\")\n",
    "    if D is None:\n",
    "        D = np.zeros((5,), dtype=float); print(\"info: using zero D\")\n",
    "    return K, D\n",
    "\n",
    "def basic_checks(K, D, img_w=None, img_h=None):\n",
    "    ok = True\n",
    "    if K.shape != (3,3):\n",
    "        print(\"err: K shape\", K.shape); ok = False\n",
    "    fx, fy = K[0,0], K[1,1]\n",
    "    cx, cy = K[0,2], K[1,2]\n",
    "    skew = K[0,1]\n",
    "    if fx <= 0 or fy <= 0:\n",
    "        print(\"err: fx/fy nonpositive\", fx, fy); ok = False\n",
    "    else:\n",
    "        print(\"ok: fx,fy\", round(fx,2), round(fy,2))\n",
    "    if abs(skew) > 1e-3 * fx:\n",
    "        print(\"warn: skew not ~0:\", skew)\n",
    "    else:\n",
    "        print(\"ok: skew small\")\n",
    "    if img_w and img_h:\n",
    "        if not (0 <= cx <= img_w):\n",
    "            print(\"warn: cx out of bounds\", cx)\n",
    "        else:\n",
    "            print(\"ok: cx\", round(cx,2))\n",
    "        if not (0 <= cy <= img_h):\n",
    "            print(\"warn: cy out of bounds\", cy)\n",
    "        else:\n",
    "            print(\"ok: cy\", round(cy,2))\n",
    "    print(\"D len\", D.shape, \"values:\", np.round(D,4).tolist())\n",
    "    if np.any(np.abs(D) > MAX_D_MAG_WARN):\n",
    "        print(\"warn: large distortion coefficients -> likely wrong\")\n",
    "    return ok\n",
    "\n",
    "def make_objp(pattern_type=\"asymmetric\", cols=COLS, rows=ROWS, spacing=SPACING):\n",
    "    if pattern_type == \"asymmetric\":\n",
    "        objp = np.zeros((cols*rows,3), np.float64)\n",
    "        idx=0\n",
    "        for j in range(rows):\n",
    "            for i in range(cols):\n",
    "                x = (2*i + (j%2))*spacing\n",
    "                y = j*spacing\n",
    "                objp[idx,0] = x; objp[idx,1] = y; idx+=1\n",
    "        return objp\n",
    "    else:\n",
    "        objp = np.zeros((cols*rows,3), np.float64)\n",
    "        grid = np.mgrid[0:cols, 0:rows].T.reshape(-1,2)\n",
    "        objp[:,:2] = grid * spacing\n",
    "        return objp\n",
    "\n",
    "def compute_reproj_rmse(objp, imgpts, rvec, tvec, K, D):\n",
    "    proj, _ = cv2.projectPoints(objp, rvec, tvec, K, D)\n",
    "    proj = proj.reshape(-1,2)\n",
    "    img = np.asarray(imgpts, dtype=np.float64).reshape(-1,2)\n",
    "    errs = np.linalg.norm(img - proj, axis=1)\n",
    "    return float(np.sqrt(np.mean(errs**2))), errs\n",
    "\n",
    "def reprojection_test_on_jsons(K, D, json_dir=JSON_DIR, pattern_type=\"asymmetric\"):\n",
    "    json_files = sorted(glob.glob(os.path.join(json_dir, \"he_record_*.json\")))\n",
    "    if not json_files:\n",
    "        print(\"info: no JSONs for reprojection test\")\n",
    "        return\n",
    "    summary = []\n",
    "    for jf in json_files:\n",
    "        try:\n",
    "            rec = json.load(open(jf,\"r\"))\n",
    "        except Exception:\n",
    "            continue\n",
    "        bd = rec.get(\"board_detection\",{})\n",
    "        if not bd.get(\"found\", False):\n",
    "            continue\n",
    "        imgpts = bd.get(\"imgpts2d\", [])\n",
    "        depths = bd.get(\"depths_m\", [])\n",
    "        imgpts = np.array(imgpts, dtype=np.float64)\n",
    "        depths_np = np.array([d if d is not None else np.nan for d in depths], dtype=np.float64)\n",
    "        mask = (~np.isnan(depths_np)) & (depths_np>0) & (depths_np<5.0)\n",
    "        if mask.sum() < 4:\n",
    "            mask = np.ones(len(depths_np), dtype=bool)\n",
    "        objp = make_objp(pattern_type)\n",
    "        m = min(len(objp), len(imgpts))\n",
    "        objp = objp[:m]; imgpts = imgpts[:m]; mask = mask[:m]\n",
    "        objp_sub = objp[mask]; imgpts_sub = imgpts[mask]\n",
    "        try:\n",
    "            ret = cv2.solvePnPRansac(objp_sub, imgpts_sub, K, D, iterationsCount=1500, reprojectionError=8.0, confidence=0.99)\n",
    "            ok = False\n",
    "            if isinstance(ret, tuple) and len(ret)==4:\n",
    "                ok, rvec, tvec, inliers = ret\n",
    "            elif isinstance(ret, tuple) and len(ret)==3:\n",
    "                rvec,tvec,inliers = ret; ok = True\n",
    "            else:\n",
    "                ok = False\n",
    "            if not ok or rvec is None or tvec is None:\n",
    "                ok2, rvec2, tvec2 = cv2.solvePnP(objp_sub, imgpts_sub, K, D, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "                if ok2:\n",
    "                    rvec, tvec = rvec2, tvec2\n",
    "                else:\n",
    "                    raise RuntimeError(\"pnp fail\")\n",
    "            rmse, errs = compute_reproj_rmse(objp_sub, imgpts_sub, rvec, tvec, K, D)\n",
    "            rmse0, _ = compute_reproj_rmse(objp_sub, imgpts_sub, rvec, tvec, K, np.zeros_like(D))\n",
    "            summary.append((os.path.basename(jf), float(rmse), float(rmse0)))\n",
    "            print(f\"{os.path.basename(jf)} rmse={rmse:.3f} rmse_noD={rmse0:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(\"warn: pnp fail for\", os.path.basename(jf))\n",
    "            continue\n",
    "    if summary:\n",
    "        rmses = np.array([s[1] for s in summary])\n",
    "        mean_rmse = float(rmses.mean())\n",
    "        print(\"summary mean rmse:\", round(mean_rmse,3))\n",
    "        bad = [(n,r0,r1) for n,r0,r1 in summary if r0 > RMSE_GOOD and r1 < r0*0.5]\n",
    "        if bad:\n",
    "            print(\"warn: frames where zero-D better (possible bad D):\")\n",
    "            for b in bad[:5]:\n",
    "                print(\" -\", b[0], \"rmse\", round(b[1],2), \"rmse_noD\", round(b[2],2))\n",
    "    else:\n",
    "        print(\"info: no reproj results\")\n",
    "\n",
    "def synthetic_projection_test(K, D, img_w=IMG_W, img_h=IMG_H):\n",
    "    xs = np.linspace(-0.2, 0.2, 5)\n",
    "    ys = np.linspace(-0.15, 0.15, 4)\n",
    "    pts = []\n",
    "    for y in ys:\n",
    "        for x in xs:\n",
    "            pts.append([x, y, 1.0])\n",
    "    obj = np.array(pts, dtype=np.float64)\n",
    "    rvec = np.zeros((3,1)); tvec = np.array([[0.0],[0.0],[0.0]])\n",
    "    proj, _ = cv2.projectPoints(obj, rvec, tvec, K, D)\n",
    "    proj = proj.reshape(-1,2)\n",
    "    inside = np.logical_and.reduce((proj[:,0]>=0, proj[:,0]<img_w, proj[:,1]>=0, proj[:,1]<img_h))\n",
    "    pct_inside = float(inside.sum())/len(obj)*100.0\n",
    "    print(\"synthetic: %d/%d points inside image (%.1f%%)\" % (inside.sum(), len(obj), pct_inside))\n",
    "    if pct_inside < 50.0:\n",
    "        print(\"warn: many projections outside image -> K or extrinsic offsets suspect\")\n",
    "    else:\n",
    "        print(\"ok: synthetic projection looks reasonable\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample = None\n",
    "    jfiles = sorted(glob.glob(os.path.join(JSON_DIR, \"he_record_*.json\")))\n",
    "    if jfiles:\n",
    "        try:\n",
    "            sample = json.load(open(jfiles[0],\"r\"))\n",
    "        except Exception:\n",
    "            sample = None\n",
    "    K, D = load_KD_from_files(sample)\n",
    "    print(\"checking K/D ..\")\n",
    "    basic_checks(K, D, img_w=IMG_W, img_h=IMG_H)\n",
    "    print(\"synthetic test ..\")\n",
    "    synthetic_projection_test(K, D)\n",
    "    print(\"reprojection test on JSONs ..\")\n",
    "    reprojection_test_on_jsons(K, D)\n",
    "    print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca10dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] depth scale (m/unit): 0.0010000000474974513\n",
      "Press 's' to save frame+pose, 'q' to quit.\n",
      "[INFO] scanned 31 json files in 'read_positions_1343'. found 31 frames with board_detection.found==True\n",
      "[[-0.04985321  0.31682823 -0.94717186  0.42136549]\n",
      " [-0.72428412  0.64152165  0.25271027  0.09237487]\n",
      " [ 0.687697    0.69861996  0.19749175  1.2390986 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0000.png he_record_0000.json found: True pattern: asymmetric\n",
      "[[-0.11646527  0.3491276  -0.92980953  0.42564791]\n",
      " [-0.76475939  0.56580121  0.30824026  0.05311458]\n",
      " [ 0.63370254  0.74697986  0.20110242  1.24770045]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0001.png he_record_0001.json found: True pattern: asymmetric\n",
      "[[ 0.09508738  0.41750451 -0.90368599  0.43919397]\n",
      " [-0.74846524  0.62850505  0.21161564  0.09254945]\n",
      " [ 0.6563217   0.65625558  0.37225051  1.17878259]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0002.png he_record_0002.json found: True pattern: asymmetric\n",
      "[[ 0.26256379  0.28369611 -0.92226719  0.44834988]\n",
      " [-0.61549632  0.78534203  0.06634892  0.18229634]\n",
      " [ 0.74311811  0.55023124  0.38081629  1.17549382]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0003.png he_record_0003.json found: True pattern: asymmetric\n",
      "[[ 0.20641551  0.23216185 -0.95052276  0.41896974]\n",
      " [-0.59737272  0.79928466  0.06549703  0.19205646]\n",
      " [ 0.77494417  0.55429676  0.30367191  1.19055274]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0004.png he_record_0004.json found: True pattern: asymmetric\n",
      "[[ 0.18619904  0.483774   -0.8551565   0.37793964]\n",
      " [-0.69464246  0.68035661  0.23363803  0.12032325]\n",
      " [ 0.69483938  0.55052484  0.46273171  1.12203093]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0005.png he_record_0005.json found: True pattern: asymmetric\n",
      "[[ 0.18622338  0.48374887 -0.85516541  0.3779472 ]\n",
      " [-0.694645    0.68036674  0.23360101  0.12033203]\n",
      " [ 0.69483033  0.55053441  0.46273393  1.12202905]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0006.png he_record_0006.json found: True pattern: asymmetric\n",
      "[[ 0.3409622   0.38681714 -0.85680644  0.47606441]\n",
      " [-0.70084513  0.71204246  0.04256332  0.15165934]\n",
      " [ 0.62654679  0.58597614  0.51387847  1.13150822]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0007.png he_record_0007.json found: True pattern: asymmetric\n",
      "[[ 0.44056996  0.41749703 -0.7947291   0.50364349]\n",
      " [-0.70067456  0.71334979 -0.01368358  0.16023881]\n",
      " [ 0.56120698  0.56287504  0.60681003  1.10447422]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0008.png he_record_0008.json found: True pattern: asymmetric\n",
      "[[ 0.50658074  0.27560073 -0.81695789  0.45228743]\n",
      " [-0.37921581  0.9221856   0.07595446  0.1049136 ]\n",
      " [ 0.77431991  0.27132628  0.57167362  1.085586  ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0009.png he_record_0009.json found: True pattern: asymmetric\n",
      "[[ 0.0079173   0.40799062 -0.91295179  0.45684228]\n",
      " [-0.84004532  0.49798313  0.21525951  0.06975681]\n",
      " [ 0.54245845  0.7652166   0.3466733   1.17878148]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0010.png he_record_0010.json found: True pattern: asymmetric\n",
      "[[ 0.10921048  0.41146613 -0.90485838  0.49628857]\n",
      " [-0.83692879  0.52920057  0.13963149  0.08130889]\n",
      " [ 0.5363052   0.74205281  0.4021621   1.17782053]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0011.png he_record_0011.json found: True pattern: asymmetric\n",
      "[[ 0.53384718  0.62054635 -0.57439483  0.56319612]\n",
      " [-0.79670499  0.59672912 -0.09578888  0.13553333]\n",
      " [ 0.28331668  0.50875985  0.81295453  0.9980647 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0012.png he_record_0012.json found: True pattern: asymmetric\n",
      "[[ 0.274457    0.35298309 -0.89446984  0.6354898 ]\n",
      " [-0.67121814  0.73641023  0.08465332  0.13056874]\n",
      " [ 0.68857793  0.57715069  0.4390416   1.09163971]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0013.png he_record_0013.json found: True pattern: asymmetric\n",
      "[[ 0.4949241   0.17264753 -0.85161198  0.61336821]\n",
      " [-0.10349471  0.98479857  0.13950134  0.12022825]\n",
      " [ 0.86275082  0.01909476  0.50526866  1.03294763]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0014.png he_record_0014.json found: True pattern: asymmetric\n",
      "[[ 0.15042853  0.19537922 -0.9691224   0.53287528]\n",
      " [-0.21107631  0.96402094  0.16158718  0.1042094 ]\n",
      " [ 0.96582506  0.18025145  0.18625618  1.07298784]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0015.png he_record_0015.json found: True pattern: asymmetric\n",
      "[[ 0.23690696  0.10277874 -0.96608055  0.52042418]\n",
      " [ 0.34678566  0.91993674  0.18291009  0.0812667 ]\n",
      " [ 0.90753226 -0.37835555  0.18229723  1.06830444]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0016.png he_record_0016.json found: True pattern: asymmetric\n",
      "[[-0.17819545  0.00206319 -0.98399295  0.53443001]\n",
      " [-0.59216423  0.79842331  0.10891162  0.14174586]\n",
      " [ 0.78586761  0.60209299 -0.14105365  1.18218552]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0017.png he_record_0017.json found: True pattern: asymmetric\n",
      "[[ 0.48434792 -0.26289156 -0.834443    0.53937682]\n",
      " [-0.39094594  0.78822351 -0.47525254  0.34718885]\n",
      " [ 0.78266747  0.55640968  0.27899803  1.07514343]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0018.png he_record_0018.json found: True pattern: asymmetric\n",
      "[[ 0.08034412 -0.16589201 -0.98286554  0.5586217 ]\n",
      " [-0.77499727  0.60970226 -0.16625998  0.26713547]\n",
      " [ 0.62683654  0.77507612 -0.07957986  1.10369188]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0019.png he_record_0019.json found: True pattern: asymmetric\n",
      "[[ 0.40721809 -0.27744125 -0.87017227  0.58848874]\n",
      " [-0.45326519  0.76575034 -0.45626427  0.38316024]\n",
      " [ 0.79292124  0.58021787  0.18607293  1.10554288]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0020.png he_record_0020.json found: True pattern: asymmetric\n",
      "[[-0.23748592  0.18014187 -0.95454143  0.46319077]\n",
      " [-0.42090938  0.86653082  0.26825293  0.11187065]\n",
      " [ 0.87546315  0.46548174 -0.12996547  1.20209198]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0021.png he_record_0021.json found: True pattern: asymmetric\n",
      "[[ 0.29798871  0.32483142 -0.89760084  0.45669272]\n",
      " [-0.14240851  0.94492506  0.29468023  0.02171675]\n",
      " [ 0.94388693  0.04001462  0.32783576  1.08262409]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0022.png he_record_0022.json found: True pattern: asymmetric\n",
      "[[-0.07226851 -0.00530442 -0.99737111  0.52614387]\n",
      " [-0.41013018  0.91168787  0.0248689   0.13471881]\n",
      " [ 0.90915923  0.41084923 -0.06806183  1.13982491]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0023.png he_record_0023.json found: True pattern: asymmetric\n",
      "[[-0.47350486  0.2195919  -0.85297863  0.44717777]\n",
      " [-0.14213368  0.93668108  0.32004151  0.06346688]\n",
      " [ 0.86924747  0.2727782  -0.41231164  1.22743399]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0024.png he_record_0024.json found: False pattern: None\n",
      "[[-0.42028658  0.10267386 -0.90156379  0.46095474]\n",
      " [-0.20491749  0.95717014  0.20453397  0.0907306 ]\n",
      " [ 0.88395023  0.27070907 -0.38124609  1.22695109]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0025.png he_record_0025.json found: True pattern: asymmetric\n",
      "[[-0.3288108   0.13208582 -0.93511325  0.45548333]\n",
      " [-0.18714358  0.96142189  0.20160662  0.08815369]\n",
      " [ 0.92566772  0.24129088 -0.29140689  1.18583589]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0026.png he_record_0026.json found: True pattern: asymmetric\n",
      "[[ 0.01189929 -0.18920384 -0.98186573  0.42061488]\n",
      " [-0.44345177  0.87909305 -0.17477394  0.19998698]\n",
      " [ 0.89621924  0.43748978 -0.0734422   1.12105866]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0027.png he_record_0027.json found: True pattern: asymmetric\n",
      "[[-0.00836874 -0.04297845 -0.99904095  0.61687827]\n",
      " [-0.7470915   0.66434631 -0.02232177  0.17827743]\n",
      " [ 0.66466853  0.7461882  -0.03766857  1.12090688]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0028.png he_record_0028.json found: True pattern: asymmetric\n",
      "[[-0.2393225  -0.00470717 -0.97092872  0.58261935]\n",
      " [-0.68861562  0.70579617  0.16631387  0.1007872 ]\n",
      " [ 0.6844949   0.70839933 -0.17215433  1.1770793 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0029.png he_record_0029.json found: True pattern: asymmetric\n",
      "[[ 0.09977439  0.08093175 -0.99171323  0.61951681]\n",
      " [-0.50776808  0.86127979  0.01920175  0.16923674]\n",
      " [ 0.85569659  0.50164448  0.12702823  1.07434077]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Saved he_img_0030.png he_record_0030.json found: True pattern: asymmetric\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.minThreshold=10; params.maxThreshold=220; params.thresholdStep=10\n",
    "params.filterByArea = True; params.minArea = 30; params.maxArea = 50000\n",
    "params.filterByCircularity = True; params.minCircularity = 0.6\n",
    "params.filterByInertia = True; params.minInertiaRatio = 0.2\n",
    "params.filterByConvexity = True; params.minConvexity = 0.6\n",
    "params.filterByColor = True; params.blobColor = 255\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "profile = pipeline.start(cfg)\n",
    "time.sleep(0.1)\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "dev = profile.get_device()\n",
    "depth_sensor = dev.first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"[INFO] depth scale (m/unit):\", depth_scale)\n",
    "\n",
    "def get_depth_m_at_pixel(depth_image, u, v, depth_scale, init_patch=3, max_patch=21):\n",
    "    h, w = depth_image.shape\n",
    "    u0 = int(round(u)); v0 = int(round(v))\n",
    "    for r in range(init_patch, max_patch+1, 2):\n",
    "        x1 = max(0, u0 - r); x2 = min(w-1, u0 + r)\n",
    "        y1 = max(0, v0 - r); y2 = min(h-1, v0 + r)\n",
    "        patch = depth_image[y1:y2+1, x1:x2+1].astype(np.float32)\n",
    "        valid = patch > 0\n",
    "        if valid.sum() > 0:\n",
    "            med = np.median(patch[valid]) * depth_scale\n",
    "            return float(med), (x1,x2,y1,y2)\n",
    "    return None, None\n",
    "\n",
    "def pixel_to_cam_point(u, v, z, K):\n",
    "    fx = float(K[0,0]); fy = float(K[1,1]); cx = float(K[0,2]); cy = float(K[1,2])\n",
    "    x = (u - cx) * z / fx\n",
    "    y = (v - cy) * z / fy\n",
    "    return np.array([x, y, z], dtype=float)\n",
    "\n",
    "def campoint_to_grip_base(p_cam, H_base_grip=None, cam2grip_R=None, cam2grip_t=None):\n",
    "    out = {}\n",
    "    if cam2grip_R is not None and cam2grip_t is not None:\n",
    "        p_grip = cam2grip_R.dot(p_cam) + cam2grip_t\n",
    "        out[\"p_grip\"] = p_grip.tolist()\n",
    "        if H_base_grip is not None:\n",
    "            Rbg = H_base_grip[:3,:3]; tbg = H_base_grip[:3,3]\n",
    "            p_base = Rbg.dot(p_grip) + tbg\n",
    "            out[\"p_base\"] = p_base.tolist()\n",
    "    return out\n",
    "\n",
    "def make_objp_for_pattern(pattern_type):\n",
    "    if pattern_type == \"asymmetric\":\n",
    "        objp = np.zeros((cols*rows,3), np.float64)\n",
    "        idxp = 0\n",
    "        for j in range(rows):\n",
    "            for i in range(cols):\n",
    "                x = (2 * i + (j % 2)) * spacing\n",
    "                y = j * spacing\n",
    "                objp[idxp,0] = x; objp[idxp,1] = y; idxp += 1\n",
    "        return objp\n",
    "    else:\n",
    "        objp = np.zeros((cols*rows,3), np.float64)\n",
    "        grid = np.mgrid[0:cols, 0:rows].T.reshape(-1,2)\n",
    "        objp[:,:2] = grid * spacing\n",
    "        return objp\n",
    "\n",
    "idx = len([n for n in os.listdir(IMG_DIR) if n.endswith(\".png\")])\n",
    "print(\"Press 's' to save frame+pose, 'q' to quit.\")\n",
    "result = load_joints_from_json_dir(dir_path=\"read_positions_1343\")\n",
    "try:\n",
    "    for row in result:\n",
    "        move_to(row, 2)\n",
    "        time.sleep(5)\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned = align.process(frames)\n",
    "        color_frame = aligned.get_color_frame()\n",
    "        depth_frame = aligned.get_depth_frame()\n",
    "        if not color_frame or not depth_frame:\n",
    "            continue\n",
    "        color = np.asanyarray(color_frame.get_data())\n",
    "        depth = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "       \n",
    "        t_wall = time.time()\n",
    "        t_mon = time.monotonic_ns()\n",
    "        img_name = f\"he_img_{idx:04d}.png\"\n",
    "        img_path = os.path.join(IMG_DIR, img_name)\n",
    "        cv2.imwrite(img_path, color)\n",
    "\n",
    "        joints = get_joint_positions()\n",
    "        H = get_flange_homogeneous()\n",
    "        H_list = H.tolist()\n",
    "        t_vec = H[:3,3].tolist()\n",
    "        quat = matrix_to_quat_xyzw(H[:3,:3])\n",
    "\n",
    "        gray = cv2.cvtColor(color, cv2.COLOR_BGR2GRAY)\n",
    "        gray_for_detect = gray\n",
    "        if UNDISTORT_FOR_DETECT and (K_mat is not None and D_vec is not None):\n",
    "            newK, _ = cv2.getOptimalNewCameraMatrix(K_mat, D_vec, (gray.shape[1], gray.shape[0]), 0)\n",
    "            gray_for_detect = cv2.undistort(color, K_mat, D_vec, None, newK)\n",
    "            gray_for_detect = cv2.cvtColor(gray_for_detect, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        board_info = {\"found\": False, \"pattern_type\": None, \"imgpts2d\": [], \"depths_m\": [], \"points_cam\": [], \"rvec\": None, \"tvec\": None, \"inliers\": None}\n",
    "        centers = None\n",
    "\n",
    "        try:\n",
    "            ret_asym, centers_asym = cv2.findCirclesGrid(gray_for_detect, (cols, rows),\n",
    "                                                            flags=cv2.CALIB_CB_ASYMMETRIC_GRID,\n",
    "                                                            blobDetector=detector)\n",
    "        except Exception:\n",
    "            ret_asym = False; centers_asym = None\n",
    "        if ret_asym:\n",
    "            centers = centers_asym.reshape(-1,2).astype(np.float32)\n",
    "            pattern_type = \"asymmetric\"\n",
    "        else:\n",
    "            try:\n",
    "                ret_sym, centers_sym = cv2.findCirclesGrid(gray_for_detect, (cols, rows),\n",
    "                                                            flags=cv2.CALIB_CB_SYMMETRIC_GRID,\n",
    "                                                            blobDetector=detector)\n",
    "            except Exception:\n",
    "                ret_sym = False; centers_sym = None\n",
    "            if ret_sym:\n",
    "                centers = centers_sym.reshape(-1,2).astype(np.float32)\n",
    "                pattern_type = \"symmetric\"\n",
    "\n",
    "        if centers is not None:\n",
    "            board_info[\"found\"] = True\n",
    "            board_info[\"pattern_type\"] = pattern_type\n",
    "            board_info[\"imgpts2d\"] = centers.tolist()\n",
    "\n",
    "            depths_list = []\n",
    "            campts_list = []\n",
    "            for i,(cx,cy) in enumerate(centers):\n",
    "                z_m, bbox = get_depth_m_at_pixel(depth, cx, cy, depth_scale, init_patch=3, max_patch=21)\n",
    "                if z_m is None:\n",
    "                    depths_list.append(None)\n",
    "                    campts_list.append(None)\n",
    "                else:\n",
    "                    depths_list.append(z_m)\n",
    "                    if K_mat is not None:\n",
    "                        p_cam = pixel_to_cam_point(float(cx), float(cy), z_m, K_mat)\n",
    "                        campts_list.append(p_cam.tolist())\n",
    "                    else:\n",
    "                        campts_list.append([None,None,z_m])\n",
    "                if SAVE_DEBUG_IMAGES and bbox is not None:\n",
    "                    x1,x2,y1,y2 = bbox\n",
    "                    patch = gray[y1:y2+1, x1:x2+1]\n",
    "                    # cv2.imwrite(os.path.join(PATCH_DIR, f\"patch_{idx:04d}_pt{i:02d}.png\"), patch)\n",
    "            board_info[\"depths_m\"] = depths_list\n",
    "            board_info[\"points_cam\"] = campts_list\n",
    "\n",
    "            if K_mat is not None:\n",
    "                objp = make_objp_for_pattern(pattern_type)\n",
    "\n",
    "                try:\n",
    "                    ok, rvec_r, tvec_r, inliers = cv2.solvePnPRansac(objp.astype(np.float64), centers.astype(np.float64), K_mat, D_vec,\n",
    "                                                                        iterationsCount=200, reprojectionError=8.0, confidence=0.99)\n",
    "                except Exception:\n",
    "                    ok = False; rvec_r = None; tvec_r = None; inliers = None\n",
    "                if ok:\n",
    "                    board_info[\"rvec\"] = rvec_r.reshape(3).tolist()\n",
    "                    board_info[\"tvec\"] = tvec_r.reshape(3).tolist()\n",
    "                    board_info[\"inliers\"] = int(len(inliers)) if inliers is not None else None\n",
    "                else:\n",
    "                    try:\n",
    "                        ok2, rvec2, tvec2 = cv2.solvePnP(objp.astype(np.float64), centers.astype(np.float64), K_mat, D_vec, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "                        if ok2:\n",
    "                            board_info[\"rvec\"] = rvec2.reshape(3).tolist()\n",
    "                            board_info[\"tvec\"] = tvec2.reshape(3).tolist()\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        rec = {\n",
    "            \"image\": img_name,\n",
    "            \"timestamp\": t_wall,\n",
    "            \"monotonic_ns\": t_mon,\n",
    "            \"camera_intrinsics\": K_FILE,\n",
    "            \"preset\": PRESET_FILE,\n",
    "            \"gripper_pose_base\": {\"H\": H_list, \"translation_m\": t_vec, \"rotation_quat_xyzw\": quat},\n",
    "            \"joints\": joints,\n",
    "            \"board_detection\": board_info,\n",
    "            \"notes\": \"\"\n",
    "        }\n",
    "        json_name = f\"he_record_{idx:04d}.json\"\n",
    "        with open(os.path.join(SAVE_DIR, json_name), 'w') as f:\n",
    "            json.dump(rec, f, indent=2)\n",
    "\n",
    "        print(\"Saved\", img_name, json_name, \"found:\", board_info[\"found\"], \"pattern:\", board_info.get(\"pattern_type\"))\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.minThreshold=10; params.maxThreshold=220; params.thresholdStep=10\n",
    "params.filterByArea = True; params.minArea = 30; params.maxArea = 50000\n",
    "params.filterByCircularity = True; params.minCircularity = 0.6\n",
    "params.filterByInertia = True; params.minInertiaRatio = 0.2\n",
    "params.filterByConvexity = True; params.minConvexity = 0.6\n",
    "params.filterByColor = True; params.blobColor = 255\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "profile = pipeline.start(cfg)\n",
    "time.sleep(0.1)\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "dev = profile.get_device()\n",
    "depth_sensor = dev.first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"[INFO] depth scale (m/unit):\", depth_scale)\n",
    "\n",
    "def get_depth_m_at_pixel(depth_image, u, v, depth_scale, init_patch=3, max_patch=21):\n",
    "    h, w = depth_image.shape\n",
    "    u0 = int(round(u)); v0 = int(round(v))\n",
    "    for r in range(init_patch, max_patch+1, 2):\n",
    "        x1 = max(0, u0 - r); x2 = min(w-1, u0 + r)\n",
    "        y1 = max(0, v0 - r); y2 = min(h-1, v0 + r)\n",
    "        patch = depth_image[y1:y2+1, x1:x2+1].astype(np.float32)\n",
    "        valid = patch > 0\n",
    "        if valid.sum() > 0:\n",
    "            med = np.median(patch[valid]) * depth_scale\n",
    "            return float(med), (x1,x2,y1,y2)\n",
    "    return None, None\n",
    "\n",
    "def pixel_to_cam_point(u, v, z, K):\n",
    "    fx = float(K[0,0]); fy = float(K[1,1]); cx = float(K[0,2]); cy = float(K[1,2])\n",
    "    x = (u - cx) * z / fx\n",
    "    y = (v - cy) * z / fy\n",
    "    return np.array([x, y, z], dtype=float)\n",
    "\n",
    "def campoint_to_grip_base(p_cam, H_base_grip=None, cam2grip_R=None, cam2grip_t=None):\n",
    "    out = {}\n",
    "    if cam2grip_R is not None and cam2grip_t is not None:\n",
    "        p_grip = cam2grip_R.dot(p_cam) + cam2grip_t\n",
    "        out[\"p_grip\"] = p_grip.tolist()\n",
    "        if H_base_grip is not None:\n",
    "            Rbg = H_base_grip[:3,:3]; tbg = H_base_grip[:3,3]\n",
    "            p_base = Rbg.dot(p_grip) + tbg\n",
    "            out[\"p_base\"] = p_base.tolist()\n",
    "    return out\n",
    "\n",
    "def make_objp_for_pattern(pattern_type):\n",
    "    if pattern_type == \"asymmetric\":\n",
    "        objp = np.zeros((cols*rows,3), np.float64)\n",
    "        idxp = 0\n",
    "        for j in range(rows):\n",
    "            for i in range(cols):\n",
    "                x = (2 * i + (j % 2)) * spacing\n",
    "                y = j * spacing\n",
    "                objp[idxp,0] = x; objp[idxp,1] = y; idxp += 1\n",
    "        return objp\n",
    "    else:\n",
    "        objp = np.zeros((cols*rows,3), np.float64)\n",
    "        grid = np.mgrid[0:cols, 0:rows].T.reshape(-1,2)\n",
    "        objp[:,:2] = grid * spacing\n",
    "        return objp\n",
    "\n",
    "idx = len([n for n in os.listdir(IMG_DIR) if n.endswith(\".png\")])\n",
    "print(\"Press 's' to save frame+pose, 'q' to quit.\")\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned = align.process(frames)\n",
    "        color_frame = aligned.get_color_frame()\n",
    "        depth_frame = aligned.get_depth_frame()\n",
    "        if not color_frame or not depth_frame:\n",
    "            continue\n",
    "        color = np.asanyarray(color_frame.get_data())\n",
    "        depth = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "        disp = color.copy()\n",
    "        if DISPLAY_SCALE != 1.0:\n",
    "            disp = cv2.resize(disp, (int(disp.shape[1]*DISPLAY_SCALE), int(disp.shape[0]*DISPLAY_SCALE)))\n",
    "        cv2.imshow(\"cap\", disp)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == ord('s'):\n",
    "            t_wall = time.time()\n",
    "            t_mon = time.monotonic_ns()\n",
    "            img_name = f\"he_img_{idx:04d}.png\"\n",
    "            img_path = os.path.join(IMG_DIR, img_name)\n",
    "            cv2.imwrite(img_path, color)\n",
    "\n",
    "            joints = get_joint_positions()\n",
    "            H = get_flange_homogeneous()\n",
    "            H_list = H.tolist()\n",
    "            t_vec = H[:3,3].tolist()\n",
    "            quat = matrix_to_quat_xyzw(H[:3,:3])\n",
    "\n",
    "            gray = cv2.cvtColor(color, cv2.COLOR_BGR2GRAY)\n",
    "            gray_for_detect = gray\n",
    "            if UNDISTORT_FOR_DETECT and (K_mat is not None and D_vec is not None):\n",
    "                newK, _ = cv2.getOptimalNewCameraMatrix(K_mat, D_vec, (gray.shape[1], gray.shape[0]), 0)\n",
    "                gray_for_detect = cv2.undistort(color, K_mat, D_vec, None, newK)\n",
    "                gray_for_detect = cv2.cvtColor(gray_for_detect, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            board_info = {\"found\": False, \"pattern_type\": None, \"imgpts2d\": [], \"depths_m\": [], \"points_cam\": [], \"rvec\": None, \"tvec\": None, \"inliers\": None}\n",
    "            centers = None\n",
    "\n",
    "            try:\n",
    "                ret_asym, centers_asym = cv2.findCirclesGrid(gray_for_detect, (cols, rows),\n",
    "                                                             flags=cv2.CALIB_CB_ASYMMETRIC_GRID,\n",
    "                                                             blobDetector=detector)\n",
    "            except Exception:\n",
    "                ret_asym = False; centers_asym = None\n",
    "            if ret_asym:\n",
    "                centers = centers_asym.reshape(-1,2).astype(np.float32)\n",
    "                pattern_type = \"asymmetric\"\n",
    "            else:\n",
    "                try:\n",
    "                    ret_sym, centers_sym = cv2.findCirclesGrid(gray_for_detect, (cols, rows),\n",
    "                                                               flags=cv2.CALIB_CB_SYMMETRIC_GRID,\n",
    "                                                               blobDetector=detector)\n",
    "                except Exception:\n",
    "                    ret_sym = False; centers_sym = None\n",
    "                if ret_sym:\n",
    "                    centers = centers_sym.reshape(-1,2).astype(np.float32)\n",
    "                    pattern_type = \"symmetric\"\n",
    "\n",
    "            if centers is not None:\n",
    "                board_info[\"found\"] = True\n",
    "                board_info[\"pattern_type\"] = pattern_type\n",
    "                board_info[\"imgpts2d\"] = centers.tolist()\n",
    "\n",
    "                depths_list = []\n",
    "                campts_list = []\n",
    "                for i,(cx,cy) in enumerate(centers):\n",
    "                    z_m, bbox = get_depth_m_at_pixel(depth, cx, cy, depth_scale, init_patch=3, max_patch=21)\n",
    "                    if z_m is None:\n",
    "                        depths_list.append(None)\n",
    "                        campts_list.append(None)\n",
    "                    else:\n",
    "                        depths_list.append(z_m)\n",
    "                        if K_mat is not None:\n",
    "                            p_cam = pixel_to_cam_point(float(cx), float(cy), z_m, K_mat)\n",
    "                            campts_list.append(p_cam.tolist())\n",
    "                        else:\n",
    "                            campts_list.append([None,None,z_m])\n",
    "                    if SAVE_DEBUG_IMAGES and bbox is not None:\n",
    "                        x1,x2,y1,y2 = bbox\n",
    "                        patch = gray[y1:y2+1, x1:x2+1]\n",
    "                        # cv2.imwrite(os.path.join(PATCH_DIR, f\"patch_{idx:04d}_pt{i:02d}.png\"), patch)\n",
    "                board_info[\"depths_m\"] = depths_list\n",
    "                board_info[\"points_cam\"] = campts_list\n",
    "\n",
    "                if K_mat is not None:\n",
    "                    objp = make_objp_for_pattern(pattern_type)\n",
    "\n",
    "                    try:\n",
    "                        ok, rvec_r, tvec_r, inliers = cv2.solvePnPRansac(objp.astype(np.float64), centers.astype(np.float64), K_mat, D_vec,\n",
    "                                                                         iterationsCount=200, reprojectionError=8.0, confidence=0.99)\n",
    "                    except Exception:\n",
    "                        ok = False; rvec_r = None; tvec_r = None; inliers = None\n",
    "                    if ok:\n",
    "                        board_info[\"rvec\"] = rvec_r.reshape(3).tolist()\n",
    "                        board_info[\"tvec\"] = tvec_r.reshape(3).tolist()\n",
    "                        board_info[\"inliers\"] = int(len(inliers)) if inliers is not None else None\n",
    "                    else:\n",
    "                        try:\n",
    "                            ok2, rvec2, tvec2 = cv2.solvePnP(objp.astype(np.float64), centers.astype(np.float64), K_mat, D_vec, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "                            if ok2:\n",
    "                                board_info[\"rvec\"] = rvec2.reshape(3).tolist()\n",
    "                                board_info[\"tvec\"] = tvec2.reshape(3).tolist()\n",
    "                        except Exception:\n",
    "                            pass\n",
    "            rec = {\n",
    "                \"image\": img_name,\n",
    "                \"timestamp\": t_wall,\n",
    "                \"monotonic_ns\": t_mon,\n",
    "                \"camera_intrinsics\": K_FILE,\n",
    "                \"preset\": PRESET_FILE,\n",
    "                \"gripper_pose_base\": {\"H\": H_list, \"translation_m\": t_vec, \"rotation_quat_xyzw\": quat},\n",
    "                \"joints\": joints,\n",
    "                \"board_detection\": board_info,\n",
    "                \"notes\": \"\"\n",
    "            }\n",
    "            json_name = f\"he_record_{idx:04d}.json\"\n",
    "            with open(os.path.join(SAVE_DIR, json_name), 'w') as f:\n",
    "                json.dump(rec, f, indent=2)\n",
    "\n",
    "            print(\"Saved\", img_name, json_name, \"found:\", board_info[\"found\"], \"pattern:\", board_info.get(\"pattern_type\"))\n",
    "            idx += 1\n",
    "\n",
    "        elif k == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739771c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rby1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
